# Named Entity Recognition (NER) with CRF and Random Forest

This project implements Named Entity Recognition (NER) using two machine learning models—Conditional Random Fields (CRF) and Random Forest—on the CoNLL-2003 dataset. The goal is to classify tokens in text into predefined NER categories (e.g., "B-PER", "I-LOC", "O"). Below is a summary of the work done for each model, including data preparation, training, evaluation, visualization, and the libraries used.

## Dataset

The CoNLL-2003 dataset is used for both models, sourced from the Hugging Face Datasets library (`datasets.load_dataset("conll2003")`). This dataset, originally from the Conference on Computational Natural Language Learning (CoNLL) 2003 shared task, contains English text annotated with named entities (Person, Location, Organization, Miscellaneous) and is split into training, validation, and test sets. It is accessed via:

- **CRF**: Loaded fully into memory without streaming.
- **Random Forest**: Loaded with streaming enabled for memory efficiency.

## Common Libraries

The following libraries are used by both models:

- `matplotlib.pyplot`: For creating plots (e.g., bar plots, heatmaps).
- `seaborn`: For enhanced visualizations with better aesthetics.
- `numpy`: For numerical operations and array handling.
- `datasets`: To load the CoNLL-2003 dataset from Hugging Face.
- `sklearn.metrics`: For evaluation metrics (classification_report, confusion_matrix, precision_recall_curve, auc).
- `collections.Counter`: For counting NER tag occurrences.
- `os`: For directory handling and file saving.

## CRF Model

### Overview

The CRF model leverages sequence labeling to predict NER tags, capturing dependencies between adjacent tokens.

### Libraries Specific to CRF

- `sklearn_crfsuite.CRF`: Implementation of the Conditional Random Field model for sequence labeling.

### Pipeline

#### Data Loading:
- Loaded CoNLL-2003 dataset fully into memory using datasets.
- Extracted token lists (`X_train`, `X_val`, `X_test`) and NER tag lists (`y_train`, `y_val`, `y_test`) for each split.

#### Feature Extraction:
- Extracted features for each word (e.g., lowercase, suffixes, case, digit status, previous/next word features, BOS/EOS markers) using pure Python logic.

#### Training:
- Trained a CRF model with `sklearn_crfsuite.CRF` using the L-BFGS algorithm, L1/L2 regularization (`c1=0.1`, `c2=0.1`), 100 iterations, and all possible transitions enabled.

#### Evaluation:
- Generated predictions for all splits using `CRF.predict`.
- Produced classification reports with `sklearn.metrics.classification_report`.
- Visualized performance with:
  - Precision-Recall curves (for "B-PER", "I-PER", "B-LOC", "O") using marginal probabilities from `CRF.predict_marginals`, plotted with `matplotlib` and `seaborn`.
  - Confusion matrices using `sklearn.metrics.confusion_matrix` and `seaborn.heatmap`.

#### Visualization:
- Plotted NER tag distributions with `seaborn.barplot`.
- Visualized top 20 transition weights between NER tags using `seaborn.barplot` and `CRF.transition_features_`.
- Compared F1-scores across splits with `matplotlib.pyplot.bar`.

### Plot Characteristics
- Font Sizes: Title: 21, Axis Labels: 18, Ticks: 14.
- Line Size: Precision-Recall curves use `linewidth=2.5`.
- Bar Styling: Bars have `edgecolor="black"` and `linewidth=1.5`.
- Storage: All plots saved in "plots/CRF/" with "CRF" appended (e.g., `NER_Tag_Distribution_in_Training_Set_CRF.png`) using `matplotlib.pyplot.savefig`.

### Outcomes
The CRF model effectively captures sequence dependencies, reflected in transition weight visualizations. Detailed performance metrics and plots are saved for analysis, highlighting strengths in specific NER categories.

## Random Forest Model

### Overview

The Random Forest model treats NER as a token-level classification task, using an ensemble of decision trees.

### Libraries Specific to Random Forest

- `sklearn.ensemble.RandomForestClassifier`: Implementation of the Random Forest model.
- `sklearn.preprocessing.LabelEncoder`: For encoding string NER tags to numeric values.
- `sklearn.feature_extraction.DictVectorizer`: For converting feature dictionaries to sparse matrices.
- `scipy.sparse`: For handling sparse matrices generated by `DictVectorizer`.
- `gc`: For garbage collection to manage memory during streaming and vectorization.

### Pipeline

#### Data Loading:
- Loaded CoNLL-2003 dataset with streaming enabled using `datasets` to process data iteratively.
- Extracted token and tag lists in chunks for memory efficiency.

#### Feature Extraction:
- Extracted features per word (e.g., lowercase, length, case, digit status, previous/next word) using pure Python logic, processed in chunks of 1000 examples.

#### Vectorization:
- Flattened feature lists and converted to sparse matrices with `DictVectorizer`.
- Encoded NER tags to numeric values using `LabelEncoder`.

#### Training:
- Trained a Random Forest with `RandomForestClassifier` (100 trees, balanced class weights, max depth of 30, parallel processing with `n_jobs=-1`).

#### Evaluation:
- Generated predictions for all splits using `RandomForestClassifier.predict`.
- Produced classification reports with `sklearn.metrics.classification_report`.
- Visualized performance with:
  - Precision-Recall curves (for "B-PER", "I-PER", "B-LOC", "O") using probability scores from `RandomForestClassifier.predict_proba`, plotted with `matplotlib` and `seaborn`.
  - Confusion matrices using `sklearn.metrics.confusion_matrix` and `seaborn.heatmap`.

#### Visualization:
- Plotted NER tag distributions with `seaborn.barplot`.
- Visualized top 20 feature importances from `RandomForestClassifier.feature_importances_` using `seaborn.barplot`.
- Compared F1-scores across splits with `matplotlib.pyplot.bar`.

### Plot Characteristics
- Font Sizes: Title: 21, Axis Labels: 18, Ticks: 14.
- Line Size: Precision-Recall curves use `linewidth=2.5`.
- Bar Styling: Bars have `edgecolor="black"` and `linewidth=1.5`.
- Storage: All plots saved in "plots/randomForest/" with "RandomForest_" prepended (e.g., `RandomForest_NER_Tag_Distribution_in_Training_Set.png`) using `matplotlib.pyplot.savefig`.

### Outcomes
The Random Forest model excels in feature-based classification, with feature importance plots highlighting key predictors. Memory-efficient streaming and chunk processing enable handling large datasets. Comprehensive evaluation plots and metrics are saved for further analysis.

## Common Elements

- **Dataset Source**: Both models use the CoNLL-2003 dataset from Hugging Face (`datasets` library).
- **Visualization**: Both include NER distribution, Precision-Recall, Confusion Matrix, and F1-score comparison plots, with consistent styling using `matplotlib` and `seaborn`.
- **Evaluation**: Both report detailed classification metrics with `sklearn.metrics` and save plots in dedicated directories ("plots/CRF/" and "plots/randomForest/") using `os`.

## Key Differences

- **Model Type**: CRF is a sequence model (`sklearn_crfsuite.CRF`); Random Forest is a token-level classifier (`sklearn.ensemble.RandomForestClassifier`).
- **Data Loading**: CRF loads fully; Random Forest streams data with `datasets`.
- **Features**: CRF uses contextual features; Random Forest uses token-specific features with `DictVectorizer` vectorization.
- **Unique Visualization**: CRF includes transition weights; Random Forest includes feature importances from `RandomForestClassifier`.
- **Libraries**: CRF uses `sklearn_crfsuite`; Random Forest uses `sklearn.ensemble`, `sklearn.preprocessing`, `sklearn.feature_extraction`, and `scipy.sparse`.

## Conclusion Remarks

This project demonstrates two approaches to NER using the CoNLL-2003 dataset from Hugging Face:

- **CRF**: Captures sequence dependencies with `sklearn_crfsuite`, ideal for structured prediction tasks.
- **Random Forest**: Leverages feature importance and parallel processing with `sklearn.ensemble`, suitable for large-scale token classification.

All plots and metrics are locally saved for detailed analysis into model performance and dataset characteristics using a robust set of Python libraries.

---

*Note: This project was worked on by Anthony Bush (5th Year student, School of Computer Science and Information Technology - The University of Juba) and Manzu Gerald Ph.D (Lecturer, The University of Juba, School of Computer Science and Information Technology).*
